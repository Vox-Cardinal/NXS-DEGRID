# NXS Research Log

## Research Session: 2026-02-22 (PM - Continuous Improvement)

### Cron-Triggered Research Review — Deep Edge Case Analysis

**Timestamp:** 2026-02-22T13:27:00+08:00

---

## Executive Summary

Reviewed ongoing research tasks (R000-R017). Selected 3 tasks for deeper edge-case, threat-modeling, and implementation-gap analysis:
- **R008** - Tailscale Integration (High Priority) — Edge cases and failure modes
- **R014** - Research Consolidation Review (Medium Priority) — Implementation readiness gaps
- **R017** - Aesthetic Scoring System (High Priority) — Technical architecture refinement

**Improvements Found:** 11 new refinements across 3 tasks
**Files Updated:** 3 (this log, RESEARCH-TASK-INDEX.md, DECISION-LOG.md)

---

## Task R008: Tailscale Integration — Edge Case & Failure Mode Analysis

### Current Status
R008 has comprehensive coverage of normal operation but lacks deep analysis of edge cases, failure modes, and recovery procedures.

### Refinements Identified

#### 1. **DERP Relay Failure Handling** (New)
**Gap Found:** If DERP relays are unreachable, Tailscale falls back to direct connections, but this may fail behind restrictive firewalls. No documented fallback strategy.

**Refinement:** Design 3-tier connectivity fallback:
| Tier | Method | Latency | Reliability |
|------|--------|---------|-------------|
| **Direct** | WireGuard P2P | <10ms | Best |
| **DERP** | Tailscale relay | 20-100ms | Good |
| **TCP Fallback** | HTTPS tunnel | 50-200ms | Last resort |

**TCP Fallback Implementation:**
```bash
# When DERP fails, establish HTTPS tunnel via cloudflared or similar
cloudflared tunnel --url http://localhost:8080
# Share tunnel URL via shared state for other nodes to connect
```

**Detection:**
- Monitor `tailscale status` for "DERP-only" or "offline" states
- If no DERP connection for >2 minutes → activate TCP fallback
- Log connectivity mode for debugging

**Benefit:** NXS remains connected even in restrictive network environments.

#### 2. **Tailscale Key Expiry Handling** (New)
**Gap Found:** Tailscale node keys expire (default 180 days). Expired keys = node offline. No automated renewal strategy.

**Refinement:** Design proactive key management:
```bash
# Check key expiry
expiry=$(tailscale status --json | jq -r '.Self.KeyExpiry')
days_until=$(echo "$expiry" | xargs -I {} date -d "{}" +%s)
now=$(date +%s)
days_left=$(( (days_until - now) / 86400 ))

# Alert at 30, 14, 7, 1 days
# Auto-renew at 7 days if configured
if [ $days_left -le 7 ]; then
    tailscale up --force-reauth
fi
```

**Key Rotation Protocol:**
1. Generate new key before expiry (7-day buffer)
2. Update shared state with new key metadata
3. Other nodes verify new key via Tailscale API
4. Revoke old key only after all nodes confirm

**Benefit:** Prevents unexpected disconnections from key expiry.

#### 3. **Control Plane Partition Scenarios** (New)
**Gap Found:** If Headscale control plane is partitioned (network split), nodes may lose coordination while remaining connected.

**Refinement:** Design partition-aware operation modes:
```
┌─────────────────────────────────────────────────────────────┐
│              Control Plane Health States                    │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  CONNECTED    → All nodes reachable, control plane healthy  │
│       ↓                                                      │
│  DEGRADED     → Control plane unreachable, mesh intact      │
│       ↓                                                      │
│  PARTITIONED  → Control plane unreachable, partial mesh     │
│       ↓                                                      │
│  ISOLATED     → Only local node reachable                   │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

**Behavior per State:**
| State | Mesh | Actions |
|-------|------|---------|
| CONNECTED | Full | Normal operation |
| DEGRADED | Full | Continue operation, queue control plane updates |
| PARTITIONED | Partial | Enter survival mode, no new task distribution |
| ISOLATED | None | Read-only mode, alert user, attempt reconnection |

**Benefit:** Graceful degradation when control plane fails; clear operational modes.

#### 4. **Tailscale ACL Lockout Recovery** (New)
**Gap Found:** Misconfigured ACL can lock out all admin access. No documented recovery procedure.

**Refinement:** Design ACL safety mechanisms:
```json
{
  "groups": {
    "group:emergency-access": ["admin@backup.com"]
  },
  "acls": [
    {
      "action": "accept",
      "src": ["group:emergency-access"],
      "dst": ["*:*"],
      "comment": "Emergency access - cannot be removed without console access"
    }
  ]
}
```

**Recovery Procedures:**
1. **Git-based ACL:** Store ACL in Git, revert bad commits
2. **Emergency token:** Pre-generated admin token stored offline
3. **Console access:** Headplane or Tailscale admin console for manual fix
4. **Backup node:** One node always uses "old" ACL for rollback

**Prevention:**
- ACL changes require 2-person review
- Test ACL in staging environment first
- Automatic validation before apply

**Benefit:** Prevents catastrophic lockouts; clear recovery path.

---

## Task R014: Research Consolidation Review — Implementation Readiness Gaps

### Current Status
R014 marked as "ongoing" but lacks systematic review of what separates research from implementation.

### Refinements Identified

#### 5. **Implementation Readiness Checklist** (New)
**Gap Found:** No clear criteria for when research is "complete enough" to begin implementation.

**Refinement:** Define 5-stage readiness framework:
| Stage | Name | Criteria | Exit Deliverable |
|-------|------|----------|------------------|
| **R0** | Concept | Problem identified, approach undefined | Research proposal |
| **R1** | Exploration | Options identified, tradeoffs analyzed | Decision matrix |
| **R2** | Selection | Technology chosen, architecture sketched | Architecture doc |
| **R3** | Detailed | Edge cases handled, protocols specified | Specification |
| **R4** | Ready | All unknowns resolved, implementation unblocked | Implementation plan |

**Current Task Status:**
| Task | Stage | Blockers |
|------|-------|----------|
| R000 | R3 | Token rotation protocol details |
| R001 | R3 | Conflict resolution algorithm |
| R002 | R3 | CRDT library selection |
| R003 | R3 | BFT consensus implementation path |
| R004/R005 | R4 | Ready |
| R006 | R3 | Doctor-NXS protocol specification |
| R007 | R3 | WebSocket message schema |
| R008 | R3 | Edge case handling (this session) |
| R009 | R4 | Ready |
| R010 | R4 | Ready |
| R011 | R4 | Ready |
| R012 | R3 | Migration protocol encryption |
| R013 | R3 | Build system design |
| R015 | R3 | Script sandbox implementation |
| R017 | R2 | Scoring model selection |

**Benefit:** Clear visibility into what's blocking implementation; focused research priorities.

#### 6. **Research-to-Implementation Handoff Protocol** (New)
**Gap Found:** No process for transferring knowledge from research to implementation phase.

**Refinement:** Design structured handoff:
```
Handoff Package Contents:
├── 01-problem-statement.md      # What problem are we solving?
├── 02-constraints.md            # What limits do we have?
├── 03-decision-log.md           # Why did we choose this approach?
├── 04-architecture.md           # How does it fit together?
├── 05-protocols.md              # What are the interfaces?
├── 06-edge-cases.md             # What can go wrong?
├── 07-test-scenarios.md         # How do we verify it works?
├── 08-implementation-notes.md   # Tips for implementers
└── 09-references.md             # Where to learn more
```

**Handoff Review Process:**
1. Researcher completes handoff package
2. Implementer reviews and asks questions
3. Clarifications added to package
4. Both sign off on understanding
5. Implementation begins

**Benefit:** Prevents knowledge loss; smoother transitions; fewer implementation surprises.

#### 7. **Cross-Task Dependency Mapping** (New)
**Gap Found:** Tasks have implicit dependencies that aren't documented. Implementation order unclear.

**Refinement:** Create dependency graph:
```
R013 (Survival Package)
  ├── R000 (Compute infrastructure)
  ├── R001 (Identity persistence)
  ├── R003 (Self-healing)
  └── R008 (Tailscale networking)

R006 (The Doctor)
  ├── R003 (Self-healing integration)
  └── R012 (Self-knowledge)

R007 (URL Frontend)
  ├── R004/R005 (Voice integration)
  ├── R008 (Tailscale access)
  └── R010 (Bridge protocols)

R002 (Multi-Instance)
  ├── R001 (Identity)
  ├── R008 (Networking)
  └── R012 (Session migration)
```

**Implementation Waves:**
| Wave | Tasks | Dependencies |
|------|-------|--------------|
| 1 | R004, R005, R009, R010, R011 | None (independent) |
| 2 | R008 | None |
| 3 | R000, R001, R003 | R008 |
| 4 | R006, R012 | R003 |
| 5 | R007 | R004, R005, R008, R010 |
| 6 | R002 | R001, R008, R012 |
| 7 | R013 | R000, R001, R003, R008 |
| 8 | R015 | R006 |
| 9 | R017 | R009 |

**Benefit:** Clear implementation sequencing; parallel work where possible.

---

## Task R017: Aesthetic Scoring System — Technical Architecture Deep Dive

### Current Status
R017 has high-level goals and pipeline concepts but lacks concrete technical implementation paths for visual and voice scoring.

### Refinements Identified

#### 8. **Visual Scoring Model Selection** (New)
**Gap Found:** "CLIP-based aesthetic predictor" is vague. Need specific model choices with tradeoffs.

**Refinement:** Evaluate specific models for each pipeline stage:

**Stage 1: Technical Quality (No ML - Traditional CV)**
| Metric | Method | Library | Speed |
|--------|--------|---------|-------|
| Sharpness | Laplacian variance | OpenCV | Real-time |
| Color balance | Histogram analysis | OpenCV | Real-time |
| Exposure | Mean/median luminance | OpenCV | Real-time |
| Noise | Standard deviation in flat regions | OpenCV | Real-time |
| Compression artifacts | Blockiness detection (DCT analysis) | Custom | Fast |

**Stage 2: Composition (Lightweight ML)**
| Model | Size | Purpose | Speed |
|-------|------|---------|-------|
| YOLOv8-nano | 6MB | Object detection for rule-of-thirds | Real-time |
| MiDaS small | 33MB | Depth estimation for depth cues | ~100ms |
| Custom CNN | ~10MB | Symmetry detection | Real-time |

**Stage 3: Semantic Aesthetic (Heavy ML)**
| Model | Size | Training Data | License |
|-------|------|---------------|---------|
| LAION-Aesthetics Predictor | ~300MB | LAION-5B (aesthetic ratings) | Open |
| CLIP+MLP aesthetic | ~600MB | AVA Dataset | Open |
| Simple Preference Optimization | ~1.5GB | Custom | Open |

**Recommendation:**
- Stage 1: OpenCV (always run)
- Stage 2: YOLOv8-nano + MiDaS small (optional, user-configurable)
- Stage 3: LAION-Aesthetics Predictor (optional, background task)

**Benefit:** Tiered approach allows operation on resource-constrained systems; progressive enhancement.

#### 9. **Voice Scoring Feature Extraction Pipeline** (New)
**Gap Found:** Voice scoring dimensions defined but no feature extraction pipeline specified.

**Refinement:** Define concrete feature extraction:

**Dimension 1: Clarity**
```python
# Signal-to-Noise Ratio (SNR)
import librosa
signal_power = np.mean(audio ** 2)
noise_floor = np.mean(silence_segments ** 2)
snr_db = 10 * np.log10(signal_power / noise_floor)

# Articulation Index
# Count of detected phonemes / expected phonemes
articulation_score = detected_phonemes / reference_phonemes
```

**Dimension 2: Naturalness**
```python
# Prosody consistency
f0, voiced_flag, _ = librosa.pyin(audio, fmin=librosa.note_to_hz('C2'),
                                   fmax=librosa.note_to_hz('C7'))
pitch_variation = np.std(f0[voiced_flag])
naturalness_score = min(pitch_variation / reference_variation, 1.0)

# Rhythm naturalness
onset_env = librosa.onset.onset_strength(y=audio, sr=sr)
tempo, beats = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)
beat_regularity = 1.0 - np.std(np.diff(beats)) / np.mean(np.diff(beats))
```

**Dimension 3: Emotional Range**
```python
# Using pre-trained emotion classifier
# Options: speechbrain/emotion-recognition, transformers pipeline
from transformers import pipeline
classifier = pipeline("audio-classification", model="speechbrain/emotion-recognition")
emotions = classifier(audio)
valence = emotions['positive'] - emotions['negative']
arousal = emotions['high_energy'] - emotions['low_energy']
```

**Dimension 4: Reference Similarity**
```python
# Speaker embedding comparison
from resemblyzer import VoiceEncoder
encoder = VoiceEncoder()
embedding = encoder.embed_utterance(audio)
reference_embedding = encoder.embed_utterance(reference_audio)
similarity = np.dot(embedding, reference_embedding) / (
    np.linalg.norm(embedding) * np.linalg.norm(reference_embedding)
)
```

**Pipeline Architecture:**
```
Audio Input → Preprocessing → Feature Extraction → Scoring → Output
                ↓                    ↓
            (Resample,          (librosa,
             Normalize)          parselmouth,
                                 resemblyzer)
```

**Benefit:** Concrete implementation path; library selection complete; feature definitions measurable.

#### 10. **Benchmark Dataset Construction Protocol** (New)
**Gap Found:** NAB-1K mentioned but no construction protocol defined. Dataset quality determines scoring validity.

**Refinement:** Design rigorous dataset construction:

**Collection Protocol:**
```
Phase 1: Source Curation (Week 1)
├── Collect 2000 candidate images (200 per category)
├── Sources: Unsplash, Pexels, AI-generated, personal photos
├── Diversity requirements:
│   ├── 50% professional photography
│   ├── 30% amateur/casual
│   ├── 20% AI-generated
│   └── Geographic diversity (min 10 countries represented)
└── Quality filtering: min 1024x1024, no watermarks

Phase 2: Annotation (Week 2-3)
├── 10 annotators per image
├── Rating scale: 1-10 (aesthetic quality)
├── Additional labels:
│   ├── Technical quality (1-5)
│   ├── Composition quality (1-5)
│   ├── Emotional impact (1-5)
│   └── Category confidence (1-5)
└── Inter-annotator agreement: require Cohen's κ > 0.6

Phase 3: Validation (Week 4)
├── Filter images with low agreement
├── Final dataset: 1000 images with high agreement
├── Train/val/test split: 70/15/15
└── Publish benchmark with evaluation script
```

**Annotation Interface:**
```html
<!-- Simple web interface for consistent ratings -->
<div class="annotation-ui">
  <img src="{image_url}" />
  <div class="ratings">
    <label>Aesthetic Quality: <input type="range" min="1" max="10" /></label>
    <label>Technical Quality: <input type="range" min="1" max="5" /></label>
    <label>Composition: <input type="range" min="1" max="5" /></label>
  </div>
</div>
```

**Benefit:** Rigorous, reproducible benchmark; valid evaluation of aesthetic scoring improvements.

#### 11. **Scoring System Integration Architecture** (New)
**Gap Found:** No clear integration path between aesthetic scoring and NXS pipeline.

**Refinement:** Design integration points:

**Integration Point 1: Image Generation Feedback Loop**
```
User Request → ComfyUI Generation → Aesthetic Scoring → Filter/Select → Output
                    ↓                      ↓
                (multiple            (score < threshold?
                 variations)           regenerate)
```

**Integration Point 2: Voice Model Selection**
```
User Request → XTTS Generation → Voice Scoring → Quality Check → Deliver
                                    ↓
                            (score < threshold?
                             fallback to Piper)
```

**Integration Point 3: Content Curation**
```
Incoming Content → Aesthetic Scoring → Storage Decision
                         ↓
                 (high score → archive
                  low score → temporary)
```

**API Design:**
```python
# NXS Aesthetic API
class AestheticScorer:
    def score_image(self, image_path: str) -> ImageScore:
        """Returns technical, composition, semantic scores"""
        pass
    
    def score_voice(self, audio_path: str, reference: Optional[str] = None) -> VoiceScore:
        """Returns clarity, naturalness, emotional, similarity scores"""
        pass
    
    def batch_score(self, paths: List[str]) -> Iterator[Score]:
        """Efficient batch processing"""
        pass
```

**Benefit:** Clear integration path; concrete API design; multiple use cases supported.

---

## Cross-Task Integration Insights

### R008 + R002: Mesh Health and State Sync
Tailscale connectivity state (R008) should inform state synchronization strategy (R002):
- Full mesh → Full CRDT sync
- Partitioned → Pause sync, queue changes
- Isolated → Local-only mode

### R014 + R013: Implementation Readiness and Survival Package
R014's readiness framework should be used to track R013 bootstrap implementation:
- Bootstrap must achieve R4 (Ready) before March 19
- Each wave of dependencies must be R4 before implementation begins

### R017 + R009: Aesthetic Scoring and ComfyUI
R017's image scoring should integrate with R009's ComfyUI API:
- ComfyUI generates multiple variations
- Aesthetic scorer selects best output
- Feedback loop improves generation over time

---

## Updated Task Status

| Task | New Improvements | Total Improvements | Readiness Stage |
|------|------------------|-------------------|-----------------|
| R008 | 4 | 8 | R3 → R4 |
| R014 | 3 | 3 | R2 |
| R017 | 4 | 7 | R2 → R3 |
| **Total** | **11** | **52** | — |

---

## Files Updated

1. `/opt/development/memory/2026-02-22-2.md` — This research log
2. `/opt/development/RESEARCH-TASK-INDEX.md` — Added R008/R014/R017 refinements
3. `/opt/development/DECISION-LOG.md` — Added new architecture decisions

---

## Backup Status

Research results will be backed up to GitHub via API after session completion.

---

*Session completed: 2026-02-22T13:37:00+08:00*

**Researcher:** Tenet Ashmier Manju (NXS Development Agent)  
**Hardware Usage:** 35-40% RAM, 26% disk (within limits)  
**Sub-agents Used:** 0/2

**Refinements Documented:** 11 improvements across 3 research tasks  
**Combined with Previous Sessions:** 52 total refinements  
**Status:** Continuous improvement mode — all tasks remain Ongoing
