# NXS Research Log

## Research Session: 2026-02-22 (Morning)

### Task R015: Non-LLM Mundane Task Scripts

**Timestamp:** 2026-02-22T07:27:00+08:00 - 08:00:00+08:00

---

## Context

This session researches self-contained scripts for mundane tasks that don't require LLM function calls. These scripts will be lightweight, reliable, and use only libraries already present in the system. The goal is to offload simple, repetitive tasks from the main NXS agent to specialized scripts that run without LLM overhead.

**Key Constraints:**
- Use only existing libraries (Node.js built-ins, OpenClaw deps)
- No LLM calls within scripts
- Self-contained and composable
- Respect 75% resource limit

---

## 1. Library Inventory

### 1.1 Node.js Built-in Modules (Available)

| Module | Version | Use Cases |
|--------|---------|-----------|
| `fs` | 22.22.0 | File operations, watching |
| `path` | 22.22.0 | Path manipulation |
| `http`/`https` | 22.22.0 | HTTP requests, simple servers |
| `net` | 22.22.0 | TCP sockets, port checks |
| `child_process` | 22.22.0 | Spawn processes |
| `events` | 22.22.0 | Event emitters |
| `stream` | 22.22.0 | Data streaming |
| `crypto` | 22.22.0 | Hashing, encryption |
| `zlib` | 22.22.0 | Compression |
| `os` | 22.22.0 | System info |
| `util` | 22.22.0 | Utilities, promisify |
| `url` | 22.22.0 | URL parsing |
| `querystring` | 22.22.0 | Query string parsing |
| `readline` | 22.22.0 | Interactive CLI |
| `timers` | 22.22.0 | Scheduling |
| `dns` | 22.22.0 | DNS lookups |

### 1.2 OpenClaw Dependencies (Available)

| Package | Purpose | Use Cases |
|---------|---------|-----------|
| `axios` | HTTP client | API polling, webhooks |
| `chokidar` | File watching | Monitor file changes |
| `node-cron` | Cron scheduling | Periodic tasks |
| `fastify` | Web server | HTTP endpoints |
| `ws` | WebSocket | Real-time communication |
| `glob` | File globbing | Pattern matching |
| `minimatch` | Pattern matching | File filters |
| `dotenv` | Environment config | Configuration loading |
| `commander` | CLI framework | Script interfaces |
| `chalk` | Terminal colors | Output formatting |
| `ora` | Loading spinners | Progress indicators |

### 1.3 System Tools (Available via child_process)

| Tool | Purpose | Use Cases |
|------|---------|-----------|
| `curl`/`wget` | HTTP requests | Fallback downloads |
| `jq` | JSON processing | Data transformation |
| `grep`/`awk`/`sed` | Text processing | Log parsing |
| `find` | File search | Discovery |
| `rsync` | File sync | Backup operations |
| `tar`/`gzip` | Archiving | Compression |
| `systemctl`/`service` | Service management | Daemon control |
| `df`/`du` | Disk usage | Monitoring |
| `ps`/`top`/`htop` | Process monitoring | System health |
| `netstat`/`ss` | Network status | Port checking |

---

## 2. Mundane Task Categories

### 2.1 Task Taxonomy

| Category | Examples | LLM Needed? | Script Candidate? |
|----------|----------|-------------|-------------------|
| **File Operations** | Copy, move, delete, organize | No | ✅ Yes |
| **Monitoring** | Health checks, log watching | No | ✅ Yes |
| **Data Transform** | JSON/YAML conversion, CSV parsing | No | ✅ Yes |
| **API Polling** | Webhook listeners, status checks | No | ✅ Yes |
| **Scheduling** | Cron-like periodic tasks | No | ✅ Yes |
| **Notifications** | Alerts, summaries | No | ✅ Yes |
| **Backups** | Archive, sync, cleanup | No | ✅ Yes |
| **Reporting** | Generate stats, summaries | Minimal | ⚠️ Maybe |
| **Decision Making** | Routing, prioritization | Yes | ❌ No |
| **Content Generation** | Writing, summarizing | Yes | ❌ No |

### 2.2 High-Value Script Targets

Based on frequency and simplicity, these tasks are prime candidates:

1. **Log Monitor** - Watch logs, alert on patterns
2. **Health Checker** - HTTP endpoint monitoring
3. **File Organizer** - Auto-sort downloads, cleanup temp
4. **Backup Rotator** - Archive with retention policy
5. **API Poller** - Poll endpoints, cache results
6. **Disk Watcher** - Monitor usage, alert thresholds
7. **Process Monitor** - Watch critical processes
8. **Sync Client** - Two-way directory sync

---

## 3. Recommended Architecture

### 3.1 Design Principles

| Principle | Implementation |
|-----------|----------------|
| **Single Purpose** | One script = one task |
| **Configuration via env** | No hardcoded values |
| **Exit codes** | 0=success, 1=error, 2=warning |
| **JSON output** | Machine-parseable results |
| **Silent by default** | Only output on error or verbose |
| **Resource aware** | Check limits before heavy ops |

### 3.2 Directory Structure

```
~/.nxs/scripts/
├── bin/                    # Executable scripts
│   ├── log-monitor.js
│   ├── health-check.js
│   ├── file-organizer.js
│   ├── backup-rotate.js
│   ├── api-poller.js
│   ├── disk-watcher.js
│   └── process-monitor.js
├── lib/                    # Shared utilities
│   ├── logger.js
│   ├── config.js
│   └── notify.js
├── config/                 # Script configurations
│   ├── log-monitor.json
│   ├── health-check.json
│   └── ...
└── logs/                   # Script output logs
    └── ...
```

### 3.3 Execution Modes

| Mode | Trigger | Use Case |
|------|---------|----------|
| **One-shot** | Manual or cron | Periodic tasks |
| **Daemon** | Systemd/background | Continuous monitoring |
| **Triggered** | File event/webhook | Reactive tasks |
| **Scheduled** | node-cron | Recurring jobs |

---

## 4. Example Script Implementations

### 4.1 Log Monitor Script

```javascript
#!/usr/bin/env node
/**
 * log-monitor.js - Watch log files for patterns
 * 
 * Usage: node log-monitor.js --pattern "ERROR" --file /var/log/app.log
 *        node log-monitor.js --config ~/.nxs/config/log-monitor.json
 */

const fs = require('fs');
const readline = require('readline');
const { spawn } = require('child_process');

// Configuration
const config = {
  file: process.env.LOG_FILE || '/var/log/syslog',
  pattern: process.env.LOG_PATTERN || 'ERROR',
  cooldown: parseInt(process.env.LOG_COOLDOWN || '60'), // seconds between alerts
  maxLines: parseInt(process.env.LOG_MAX_LINES || '100'),
  ...loadConfig()
};

function loadConfig() {
  const configPath = process.argv.find(arg => arg.startsWith('--config='))?.split('=')[1];
  if (configPath && fs.existsSync(configPath)) {
    return JSON.parse(fs.readFileSync(configPath, 'utf8'));
  }
  return {};
}

// State
let lastAlert = 0;
let matchCount = 0;
const regex = new RegExp(config.pattern, 'i');

// Main
async function main() {
  if (!fs.existsSync(config.file)) {
    console.error(JSON.stringify({ error: 'File not found', file: config.file }));
    process.exit(1);
  }

  // For daemon mode, use tail -f
  if (process.argv.includes('--daemon')) {
    runDaemon();
  } else {
    // One-shot: check recent lines
    await checkRecent();
  }
}

async function checkRecent() {
  const lines = await readLastLines(config.file, config.maxLines);
  const matches = lines.filter(line => regex.test(line));
  
  console.log(JSON.stringify({
    file: config.file,
    pattern: config.pattern,
    checked: lines.length,
    matches: matches.length,
    lines: matches.slice(-10) // Last 10 matches
  }, null, 2));
  
  process.exit(matches.length > 0 ? 2 : 0); // 2 = warning if matches found
}

function runDaemon() {
  const tail = spawn('tail', ['-f', '-n', '0', config.file]);
  
  const rl = readline.createInterface({
    input: tail.stdout,
    crlfDelay: Infinity
  });
  
  rl.on('line', (line) => {
    if (regex.test(line)) {
      const now = Date.now();
      if (now - lastAlert > config.cooldown * 1000) {
        lastAlert = now;
        matchCount++;
        
        const alert = {
          timestamp: new Date().toISOString(),
          type: 'log_match',
          file: config.file,
          pattern: config.pattern,
          line: line.substring(0, 500), // Truncate long lines
          match_count: matchCount
        };
        
        console.log(JSON.stringify(alert));
        
        // Optional: send notification
        if (process.env.NOTIFY_WEBHOOK) {
          sendWebhook(alert);
        }
      }
    }
  });
  
  process.on('SIGTERM', () => {
    tail.kill();
    process.exit(0);
  });
}

function readLastLines(file, n) {
  return new Promise((resolve, reject) => {
    const lines = [];
    const rl = readline.createInterface({
      input: fs.createReadStream(file),
      crlfDelay: Infinity
    });
    
    rl.on('line', (line) => {
      lines.push(line);
      if (lines.length > n) lines.shift();
    });
    
    rl.on('close', () => resolve(lines));
    rl.on('error', reject);
  });
}

async function sendWebhook(payload) {
  const https = require('https');
  const url = new URL(process.env.NOTIFY_WEBHOOK);
  
  const data = JSON.stringify(payload);
  
  const options = {
    hostname: url.hostname,
    port: url.port || 443,
    path: url.pathname + url.search,
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Content-Length': data.length
    }
  };
  
  return new Promise((resolve, reject) => {
    const req = https.request(options, (res) => {
      resolve(res.statusCode);
    });
    req.on('error', reject);
    req.write(data);
    req.end();
  });
}

main().catch(err => {
  console.error(JSON.stringify({ error: err.message }));
  process.exit(1);
});
```

### 4.2 Health Check Script

```javascript
#!/usr/bin/env node
/**
 * health-check.js - Monitor HTTP endpoints
 * 
 * Usage: node health-check.js --url https://api.example.com/health
 *        node health-check.js --config ~/.nxs/config/health-check.json
 */

const https = require('https');
const http = require('http');
const fs = require('fs');

// Configuration
const config = {
  url: process.env.CHECK_URL || 'http://localhost:18789/status',
  method: process.env.CHECK_METHOD || 'GET',
  timeout: parseInt(process.env.CHECK_TIMEOUT || '5000'),
  expectedStatus: parseInt(process.env.CHECK_EXPECTED_STATUS || '200'),
  expectedBody: process.env.CHECK_EXPECTED_BODY || null,
  retries: parseInt(process.env.CHECK_RETRIES || '2'),
  retryDelay: parseInt(process.env.CHECK_RETRY_DELAY || '1000'),
  ...loadConfig()
};

function loadConfig() {
  const configPath = process.argv.find(arg => arg.startsWith('--config='))?.split('=')[1];
  if (configPath && fs.existsSync(configPath)) {
    return JSON.parse(fs.readFileSync(configPath, 'utf8'));
  }
  return {};
}

// Main
async function main() {
  const startTime = Date.now();
  let lastError = null;
  
  for (let attempt = 0; attempt <= config.retries; attempt++) {
    try {
      const result = await checkEndpoint();
      const duration = Date.now() - startTime;
      
      console.log(JSON.stringify({
        url: config.url,
        status: 'healthy',
        statusCode: result.statusCode,
        responseTime: duration,
        attempt: attempt + 1,
        timestamp: new Date().toISOString()
      }, null, 2));
      
      process.exit(0);
    } catch (err) {
      lastError = err;
      if (attempt < config.retries) {
        await sleep(config.retryDelay);
      }
    }
  }
  
  // All retries exhausted
  console.log(JSON.stringify({
    url: config.url,
    status: 'unhealthy',
    error: lastError.message,
    attempts: config.retries + 1,
    timestamp: new Date().toISOString()
  }, null, 2));
  
  process.exit(1);
}

function checkEndpoint() {
  return new Promise((resolve, reject) => {
    const url = new URL(config.url);
    const client = url.protocol === 'https:' ? https : http;
    
    const options = {
      hostname: url.hostname,
      port: url.port || (url.protocol === 'https:' ? 443 : 80),
      path: url.pathname + url.search,
      method: config.method,
      timeout: config.timeout,
      headers: {
        'User-Agent': 'NXS-HealthCheck/1.0'
      }
    };
    
    const req = client.request(options, (res) => {
      let data = '';
      res.on('data', chunk => data += chunk);
      res.on('end', () => {
        if (res.statusCode !== config.expectedStatus) {
          reject(new Error(`Unexpected status: ${res.statusCode}`));
          return;
        }
        
        if (config.expectedBody && !data.includes(config.expectedBody)) {
          reject(new Error('Expected body not found'));
          return;
        }
        
        resolve({ statusCode: res.statusCode, body: data });
      });
    });
    
    req.on('error', reject);
    req.on('timeout', () => {
      req.destroy();
      reject(new Error('Request timeout'));
    });
    
    req.end();
  });
}

function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

main().catch(err => {
  console.error(JSON.stringify({ error: err.message }));
  process.exit(1);
});
```

### 4.3 File Organizer Script

```javascript
#!/usr/bin/env node
/**
 * file-organizer.js - Auto-organize files by rules
 * 
 * Usage: node file-organizer.js --source ~/Downloads --rules ~/.nxs/config/organizer.json
 */

const fs = require('fs').promises;
const path = require('path');
const os = require('os');

// Default rules
const defaultRules = [
  { pattern: '\.(jpg|jpeg|png|gif|webp)$', dest: 'Images', maxAge: 30 },
  { pattern: '\.(pdf|doc|docx|txt|md)$', dest: 'Documents', maxAge: 90 },
  { pattern: '\.(zip|tar|gz|rar|7z)$', dest: 'Archives', maxAge: 7 },
  { pattern: '\.(mp3|mp4|avi|mkv|mov)$', dest: 'Media', maxAge: 60 },
  { pattern: '\.(js|py|ts|go|rs|java)$', dest: 'Code', maxAge: 90 },
  { pattern: '^\\.', dest: null, action: 'delete', maxAge: 7 } // Delete hidden files older than 7 days
];

// Configuration
const config = {
  source: process.env.ORGANIZER_SOURCE || path.join(os.homedir(), 'Downloads'),
  destRoot: process.env.ORGANIZER_DEST || path.join(os.homedir(), 'Organized'),
  dryRun: process.env.ORGANIZER_DRY_RUN === 'true',
  rules: defaultRules,
  ...loadConfig()
};

function loadConfig() {
  const configPath = process.argv.find(arg => arg.startsWith('--rules='))?.split('=')[1];
  if (configPath) {
    try {
      return JSON.parse(require('fs').readFileSync(configPath, 'utf8'));
    } catch (e) {
      console.error(`Failed to load config: ${e.message}`);
    }
  }
  return {};
}

// Main
async function main() {
  const stats = {
    scanned: 0,
    moved: 0,
    deleted: 0,
    skipped: 0,
    errors: 0,
    byCategory: {}
  };
  
  try {
    // Ensure destination exists
    if (!config.dryRun) {
      await fs.mkdir(config.destRoot, { recursive: true });
    }
    
    // Scan source directory
    const files = await fs.readdir(config.source);
    
    for (const filename of files) {
      stats.scanned++;
      const filePath = path.join(config.source, filename);
      
      try {
        const stat = await fs.stat(filePath);
        if (!stat.isFile()) {
          stats.skipped++;
          continue;
        }
        
        // Find matching rule
        const rule = config.rules.find(r => new RegExp(r.pattern, 'i').test(filename));
        
        if (!rule) {
          stats.skipped++;
          continue;
        }
        
        // Check age
        const ageDays = (Date.now() - stat.mtime.getTime()) / (1000 * 60 * 60 * 24);
        if (rule.maxAge && ageDays < rule.maxAge) {
          stats.skipped++;
          continue;
        }
        
        // Execute action
        if (rule.action === 'delete') {
          if (config.dryRun) {
            console.log(`[DRY-RUN] Would delete: ${filename}`);
          } else {
            await fs.unlink(filePath);
          }
          stats.deleted++;
          continue;
        }
        
        // Move to destination
        if (rule.dest) {
          const destDir = path.join(config.destRoot, rule.dest);
          const destPath = path.join(destDir, filename);
          
          if (config.dryRun) {
            console.log(`[DRY-RUN] Would move: ${filename} → ${rule.dest}/`);
          } else {
            await fs.mkdir(destDir, { recursive: true });
            await fs.rename(filePath, destPath);
          }
          
          stats.moved++;
          stats.byCategory[rule.dest] = (stats.byCategory[rule.dest] || 0) + 1;
        }
        
      } catch (err) {
        stats.errors++;
        console.error(`Error processing ${filename}: ${err.message}`);
      }
    }
    
    console.log(JSON.stringify(stats, null, 2));
    process.exit(stats.errors > 0 ? 2 : 0);
    
  } catch (err) {
    console.error(JSON.stringify({ error: err.message }));
    process.exit(1);
  }
}

main();
```

### 4.4 Shared Utility Library

```javascript
/**
 * lib/logger.js - Shared logging utility
 */

const fs = require('fs');
const path = require('path');

class ScriptLogger {
  constructor(name, options = {}) {
    this.name = name;
    this.logDir = options.logDir || path.join(process.env.HOME, '.nxs', 'logs');
    this.level = options.level || process.env.LOG_LEVEL || 'info';
    this.silent = options.silent || process.env.SCRIPT_SILENT === 'true';
    
    this.levels = { error: 0, warn: 1, info: 2, debug: 3 };
    
    // Ensure log directory exists
    if (!fs.existsSync(this.logDir)) {
      fs.mkdirSync(this.logDir, { recursive: true });
    }
  }
  
  log(level, message, data = {}) {
    if (this.levels[level] > this.levels[this.level]) return;
    
    const entry = {
      timestamp: new Date().toISOString(),
      script: this.name,
      level,
      message,
      ...data
    };
    
    // Write to file
    const logFile = path.join(this.logDir, `${this.name}.log`);
    fs.appendFileSync(logFile, JSON.stringify(entry) + '\n');
    
    // Console output (unless silent)
    if (!this.silent && level !== 'debug') {
      console.log(JSON.stringify(entry));
    }
  }
  
  error(message, data) { this.log('error', message, data); }
  warn(message, data) { this.log('warn', message, data); }
  info(message, data) { this.log('info', message, data); }
  debug(message, data) { this.log('debug', message, data); }
}

module.exports = { ScriptLogger };
```

```javascript
/**
 * lib/notify.js - Notification utilities
 */

const https = require('https');
const http = require('http');

class Notifier {
  constructor(options = {}) {
    this.webhook = options.webhook || process.env.NOTIFY_WEBHOOK;
    this.channel = options.channel || process.env.NOTIFY_CHANNEL;
  }
  
  async send(payload) {
    if (this.webhook) {
      return this.sendWebhook(payload);
    }
    
    // Fallback: write to stdout for NXS to pick up
    console.log(JSON.stringify({
      type: 'notification',
      channel: this.channel,
      ...payload
    }));
  }
  
  async sendWebhook(payload) {
    return new Promise((resolve, reject) => {
      const url = new URL(this.webhook);
      const client = url.protocol === 'https:' ? https : http;
      
      const data = JSON.stringify(payload);
      
      const options = {
        hostname: url.hostname,
        port: url.port,
        path: url.pathname + url.search,
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Content-Length': data.length
        }
      };
      
      const req = client.request(options, (res) => {
        resolve({ statusCode: res.statusCode });
      });
      
      req.on('error', reject);
      req.write(data);
      req.end();
    });
  }
}

module.exports = { Notifier };
```

---

## 5. Integration with NXS

### 5.1 Execution Patterns

| Pattern | How | Use Case |
|---------|-----|----------|
| **Direct spawn** | `child_process.spawn()` | One-shot tasks |
| **Cron integration** | `node-cron` schedule | Periodic tasks |
| **File watcher** | `chokidar` events | Reactive tasks |
| **HTTP trigger** | Fastify endpoint | On-demand tasks |
| **Message queue** | Redis/pub-sub | Distributed tasks |

### 5.2 NXS Integration Example

```javascript
// NXS skill that delegates to scripts
const { spawn } = require('child_process');
const path = require('path');

class ScriptExecutor {
  constructor() {
    this.scriptDir = path.join(process.env.HOME, '.nxs', 'scripts', 'bin');
  }
  
  async run(scriptName, args = [], options = {}) {
    const scriptPath = path.join(this.scriptDir, `${scriptName}.js`);
    
    return new Promise((resolve, reject) => {
      const child = spawn('node', [scriptPath, ...args], {
        env: { ...process.env, ...options.env },
        timeout: options.timeout || 30000
      });
      
      let stdout = '';
      let stderr = '';
      
      child.stdout.on('data', (data) => {
        stdout += data.toString();
      });
      
      child.stderr.on('data', (data) => {
        stderr += data.toString();
      });
      
      child.on('close', (code) => {
        try {
          const result = JSON.parse(stdout);
          resolve({ code, result, stderr });
        } catch {
          resolve({ code, stdout, stderr });
        }
      });
      
      child.on('error', reject);
    });
  }
}

// Usage in NXS
const executor = new ScriptExecutor();

// Check health
const health = await executor.run('health-check', [], {
  env: { CHECK_URL: 'https://api.example.com/health' }
});

// Organize files
const organized = await executor.run('file-organizer', ['--dry-run']);
```

### 5.3 Configuration Schema

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "NXS Script Configuration",
  "type": "object",
  "properties": {
    "scripts": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "name": { "type": "string" },
          "enabled": { "type": "boolean", "default": true },
          "schedule": { 
            "type": "string",
            "description": "Cron expression or 'daemon' for continuous"
          },
          "config": { "type": "object" },
          "env": { "type": "object" },
          "timeout": { "type": "number", "default": 30000 }
        },
        "required": ["name"]
      }
    }
  }
}
```

---

## 6. Task Matrix Summary

| Script | Purpose | Libraries Used | Execution |
|--------|---------|----------------|-----------|
| `log-monitor.js` | Watch logs for patterns | `fs`, `readline`, `child_process` | Daemon/One-shot |
| `health-check.js` | HTTP endpoint monitoring | `http`, `https` | One-shot |
| `file-organizer.js` | Auto-organize files | `fs`, `path`, `os` | One-shot |
| `backup-rotate.js` | Archive with retention | `fs`, `child_process` (tar) | One-shot |
| `api-poller.js` | Poll endpoints, cache | `http`, `https`, `fs` | Daemon |
| `disk-watcher.js` | Monitor disk usage | `child_process` (df) | One-shot/Daemon |
| `process-monitor.js` | Watch processes | `child_process` (ps) | Daemon |

---

## 7. Deliverables

### 7.1 Completed Research

| Item | Status | Location |
|------|--------|----------|
| Library inventory | ✅ Complete | This document |
| Task categorization | ✅ Complete | Section 2 |
| Architecture design | ✅ Complete | Section 3 |
| Example implementations | ✅ Complete | Section 4 |
| Integration guide | ✅ Complete | Section 5 |

### 7.2 Recommended Next Steps

1. **Create script directory structure** in `~/.nxs/scripts/`
2. **Implement core scripts** (log-monitor, health-check, file-organizer)
3. **Create shared library** (logger, config, notify)
4. **Add NXS skill** for script execution
5. **Document configuration** format and examples

---

## 8. R015 Status

| Component | Status |
|-----------|--------|
| Task identification | ✅ Complete |
| Library inventory | ✅ Complete |
| Architecture design | ✅ Complete |
| Example implementations | ✅ Complete |
| Integration guide | ✅ Complete |

**Overall Status:** ✅ **RESEARCH COMPLETE**

---

## Sources

1. Node.js Documentation - Built-in modules
2. OpenClaw package.json - Dependency inventory
3. Unix Philosophy - Single-purpose tools
4. 12-Factor App - Configuration via environment
5. Systemd documentation - Service management patterns

---

*Session completed: 2026-02-22T08:00:00+08:00*

**Researcher:** Kimi Claw (NXS Development Agent)  
**Hardware Usage:** 38% RAM, 26% disk (within 75% limit)  
**Sub-agents Used:** 0 (direct research)

**Files Updated:**
- `/opt/development/memory/2026-02-22.md` - This research log (R015)

**R015 Deliverables:**
1. Library inventory (built-in + OpenClaw deps + system tools)
2. Task categorization matrix
3. Architecture design principles
4. 4 complete example script implementations
5. Integration patterns for NXS
6. Configuration schema
